---
title: "Lab 6"
output:
  github_document:
  html_document:
    html_preview: false
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
options(repos = c(CRAN = "http://cran.rstudio.com"))
library(tidyverse)
library(tidytext)
library(tibble)


```

##download the data
```{r}
fn <- "mtsamples.csv"
if (!file.exists(fn))
  download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv", destfile = fn)

mtsamples <- read.csv(fn)
mtsamples <- as_tibble(mtsamples)

```

##Q1 hoe many and how are specialties distributed?
```{r dist-of-specialties}
specialties <- mtsamples %>%
  count(medical_specialty)

specialties %>%
  arrange(desc(n)) %>%
  top_n(15) %>%
  knitr::kable()

```


```{r}
# Method 1 (not that pretty)
ggplot(mtsamples, aes(x = medical_specialty)) +
  geom_histogram(stat = "count") +
  coord_flip()
```
```{r}
# Method 2
ggplot(specialties, aes(x = n, y = fct_reorder(medical_specialty, n))) +
  geom_col()

```

These are not evenly (uniformly) distributed.

##Q2 
```{r token_transcript, cache=TRUE}
mtsamples %>%
  unnest_tokens(output = word, input = transcription) %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(word, n))) +
    geom_col()


```



The word "patient" seems to be important, but we observe a lot of stopwords


#Q3
```{r}
mtsamples %>%
  unnest_tokens(output = word, input = transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = "word") %>%
  # Using regular expressions to remove numbers
  filter(!grepl(pattern = "^[0-9]+$", x = word)) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(word, n))) +
    geom_col()

```



Looking better~~, but we don't like the numbers~~.

#Q4

```{r}
mtsamples %>%
  unnest_ngrams(output = bigram, input = transcription, n = 2) %>%
  count(bigram, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(bigram, n))) +
    geom_col()

  
```
Using bi-grams is not very informative, letâ€™s try with tri-grams instead.
```{r}
mtsamples %>%
  unnest_ngrams(output = trigram, input = transcription, n = 3) %>%
  count(trigram, sort = TRUE) %>%
  top_n(20) %>%
  ggplot(aes(x = n, y = fct_reorder(trigram, n))) +
    geom_col()

```

#Q5
```{r}

bigrams <- mtsamples %>%
  unnest_ngrams(output = bigram, input = transcription, n = 2) %>%
  separate(bigram, into = c("w1", "w2"), sep = " ") %>%
  filter((w1 == "history") | (w2 == "history"))

bigrams %>%
  filter(w1 == "history") %>%
  select(w1, w2) %>%
  count(w2, sort = TRUE)


bigrams %>%
  filter(w2 == "history") %>%
  select(w1, w2) %>%
  count(w1, sort = TRUE)


bigrams %>%
  filter(w2 == "history")%>%
  select(w1, w2) %>%
  count(w1, sort = TRUE)

```

Since we are looking at single words again, it is good idea to treat these as single tokens. So let's remove the stopwords and the numbers

```{r}
bigrams %>%
  filter(w1 == "history") %>%
  filter(!(w2 %in% stop_words$word) & !grepl("^[0-9]+$", w2)) %>%
  count(w2, sort = TRUE) %>%
  top_n(10) %>%
  knitr::kable()

```
```{r}
bigrams %>%
  filter(w2 == "history") %>%
  filter(!(w1 %in% stop_words$word) & !grepl("^[0-9]+$", w1)) %>%
  count(w1, sort = TRUE) %>%
  top_n(10) %>%
  knitr::kable()

```


